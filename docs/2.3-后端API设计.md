# 2.3 后端 API 设计

## MVP API 规范

### 核心原则
- **极简**: MVP 只有 1 个核心 API
- **无认证**: 无需 token，直接调用
- **流式响应**: 使用 SSE 实现打字机效果

---

## 1. 唯一的核心 API

### 生成洞察 (流式)

**端点**: `POST /api/v1/insights/generate`

**请求格式**:
```http
POST /api/v1/insights/generate
Content-Type: application/json

{
  "selected_text": "康德的绝对命令",
  "context": "在伦理学中,康德的绝对命令是一个核心概念。它要求我们的行为准则能够成为普遍法则。这种道义论的观点与功利主义形成鲜明对比。",
  "intent": "explain"
}
```

**字段说明**:
- `selected_text` (必填): 用户划词选中的文本
- `context` (必填): 上下文，包含选中文本所在句子及前后句
- `intent` (必填): 用户意图
  - `explain`: "这是什么意思？"
  - `analyze`: "作者为什么这么说？"
  - `counter`: "有不同的看法吗？" (V2.0)
- `custom_question` (可选, V2.0): 用户自定义问题

**响应格式 (SSE)**:
```
Content-Type: text/event-stream
Cache-Control: no-cache
Connection: keep-alive

data: {"type": "start", "request_id": "req_123"}

data: {"type": "delta", "content": "康德"}

data: {"type": "delta", "content": "的"}

data: {"type": "delta", "content": "绝对命令"}

data: {"type": "delta", "content": "（Categorical"}

data: {"type": "delta", "content": " Imperative）"}

data: {"type": "complete", "full_content": "康德的绝对命令（Categorical Imperative）...", "metadata": {"model": "claude-3-5-sonnet-20241022", "tokens": 245, "duration_ms": 1250}}

```

**事件类型**:
```typescript
type SSEEvent =
  | { type: "start", request_id: string }
  | { type: "delta", content: string }
  | { type: "complete", full_content: string, metadata: { model: string, tokens: number, duration_ms: number } }
  | { type: "error", message: string, code: string }
```

---

## 2. FastAPI 实现

### 2.1 主应用 (main.py)

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api import insights

app = FastAPI(
    title="InsightReader API",
    version="1.0.0-mvp",
    description="上下文智能探针 API"
)

# CORS 配置（MVP 宽松，生产环境需收紧）
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # 生产环境改为具体域名
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 注册路由
app.include_router(insights.router, prefix="/api/v1")

@app.get("/health")
async def health_check():
    return {"status": "ok", "version": "1.0.0-mvp"}
```

### 2.2 洞察生成 API (api/insights.py)

```python
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
import json
import time

from app.services.ai_service import AIService
from app.services.context_extractor import ContextExtractor

router = APIRouter(tags=["insights"])

class InsightRequest(BaseModel):
    selected_text: str = Field(..., min_length=1, max_length=500)
    context: str = Field(..., min_length=10, max_length=2000)
    intent: str = Field(..., pattern="^(explain|analyze|counter)$")
    custom_question: str | None = Field(None, max_length=200)  # V2.0

class InsightResponse(BaseModel):
    content: str
    model: str
    tokens: int

@router.post("/insights/generate")
async def generate_insight(request: InsightRequest):
    """
    流式生成洞察卡片

    Args:
        request: 包含选中文本、上下文和意图的请求

    Returns:
        SSE 流式响应
    """
    ai_service = AIService()
    request_id = f"req_{int(time.time() * 1000)}"
    start_time = time.time()

    async def event_stream():
        try:
            # 开始事件
            yield f"data: {json.dumps({'type': 'start', 'request_id': request_id})}\n\n"

            full_content = ""
            token_count = 0

            # 流式生成
            async for chunk in ai_service.generate_insight_stream(
                selected_text=request.selected_text,
                context=request.context,
                intent=request.intent,
                custom_question=request.custom_question
            ):
                full_content += chunk
                token_count += 1  # 简化计算，实际应该用 tiktoken

                yield f"data: {json.dumps({'type': 'delta', 'content': chunk})}\n\n"

            # 完成事件
            duration_ms = int((time.time() - start_time) * 1000)
            metadata = {
                "model": ai_service.model_used,
                "tokens": token_count,
                "duration_ms": duration_ms
            }

            yield f"data: {json.dumps({'type': 'complete', 'full_content': full_content, 'metadata': metadata})}\n\n"

        except Exception as e:
            error_data = {
                "type": "error",
                "message": str(e),
                "code": "GENERATION_FAILED"
            }
            yield f"data: {json.dumps(error_data)}\n\n"

    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # 禁用 Nginx 缓冲
        }
    )
```

### 2.3 AI 服务 (services/ai_service.py)

```python
from anthropic import AsyncAnthropic
import os
from app.utils.prompt_templates import PromptTemplates

class AIService:
    def __init__(self):
        self.client = AsyncAnthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        self.model_used = ""

    def _select_model(self, intent: str, text_length: int) -> str:
        """根据意图和文本长度选择模型"""
        if intent == "explain" and text_length < 10:
            return "claude-3-haiku-20240307"  # 简单解释用便宜模型
        else:
            return "claude-3-5-sonnet-20241022"  # 复杂分析用强模型

    async def generate_insight_stream(
        self,
        selected_text: str,
        context: str,
        intent: str,
        custom_question: str | None = None
    ):
        """流式生成洞察"""

        # 选择模型
        self.model_used = self._select_model(intent, len(selected_text))

        # 构建 Prompt
        system_prompt = PromptTemplates.get_system_prompt(intent)
        user_prompt = PromptTemplates.get_user_prompt(
            intent=intent,
            selected_text=selected_text,
            context=context,
            custom_question=custom_question
        )

        # 调用 Claude API (流式)
        async with self.client.messages.stream(
            model=self.model_used,
            max_tokens=1000,
            temperature=0.7,
            system=system_prompt,
            messages=[{"role": "user", "content": user_prompt}]
        ) as stream:
            async for text in stream.text_stream:
                yield text
```

### 2.4 Prompt 模板 (utils/prompt_templates.py)

```python
class PromptTemplates:

    SYSTEM_PROMPTS = {
        "explain": """你是一位知识渊博的教育者，擅长用通俗易懂的语言解释复杂概念。
你的回答应该：
1. 简洁明了，避免冗长
2. 从基础开始，循序渐进
3. 使用类比和例子帮助理解
4. 中文回答，使用 Markdown 格式""",

        "analyze": """你是一位批判性思维专家，擅长分析文本的逻辑结构和论证手法。
你的回答应该：
1. 指出论证类型（演绎、归纳、类比等）
2. 分析前提和结论
3. 评估论证强度
4. 指出潜在漏洞或偏见
5. 中文回答，使用 Markdown 格式""",

        "counter": """你是一位思维开阔的分析师，能从多个角度看待问题。
你的回答应该：
1. 提供反方观点或不同视角
2. 说明这些观点的依据
3. 保持客观，不偏袒任何一方
4. 中文回答，使用 Markdown 格式"""
    }

    @classmethod
    def get_system_prompt(cls, intent: str) -> str:
        return cls.SYSTEM_PROMPTS.get(intent, cls.SYSTEM_PROMPTS["explain"])

    @classmethod
    def get_user_prompt(
        cls,
        intent: str,
        selected_text: str,
        context: str,
        custom_question: str | None = None
    ) -> str:
        """构建用户 Prompt"""

        if custom_question:
            # V2.0: 用户自定义问题
            return f"""选中的文本：{selected_text}

上下文：
{context}

用户的问题：{custom_question}

请基于上下文回答用户的问题。"""

        # 预设问题
        if intent == "explain":
            return f"""请解释以下文本的含义：

**选中的文本**：{selected_text}

**上下文**：
{context}

请简要解释：
1. 这个概念/术语的含义
2. 相关的背景知识
3. 为什么它在这里被提及"""

        elif intent == "analyze":
            return f"""请分析以下文本的论证逻辑：

**选中的文本**：{selected_text}

**上下文**：
{context}

请分析：
1. 作者的论证类型
2. 主要论据和结论
3. 论证的强弱
4. 可能的漏洞"""

        elif intent == "counter":
            return f"""请对以下观点提供不同的视角：

**选中的文本**：{selected_text}

**上下文**：
{context}

请提供：
1. 可能的反对观点
2. 不同学派或角度的看法
3. 这个话题的争议点"""

        return ""
```

---

## 3. 错误处理

### 3.1 错误码定义

```python
class ErrorCode:
    # 请求相关 (400x)
    INVALID_REQUEST = "4001"
    TEXT_TOO_LONG = "4002"
    INVALID_INTENT = "4003"

    # AI 服务相关 (500x)
    AI_SERVICE_ERROR = "5001"
    GENERATION_TIMEOUT = "5002"
    RATE_LIMIT_EXCEEDED = "5003"
```

### 3.2 异常处理

```python
from fastapi import HTTPException, Request
from fastapi.responses import JSONResponse

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": f"{exc.status_code}00",
                "message": exc.detail
            }
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "5000",
                "message": "服务器内部错误"
            }
        }
    )
```

---

## 4. 请求限流 (生产环境)

```python
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@router.post("/insights/generate")
@limiter.limit("20/minute")  # 每分钟最多 20 次请求
async def generate_insight(request: Request, data: InsightRequest):
    ...
```

---

## 5. API 文档

FastAPI 自动生成的文档：

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`
- **OpenAPI JSON**: `http://localhost:8000/openapi.json`

---

## 6. 环境变量配置

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-xxx

# 可选配置
MAX_CONTEXT_LENGTH=2000
DEFAULT_MODEL=claude-3-5-sonnet-20241022
ENABLE_RATE_LIMIT=true
```

```python
# config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    anthropic_api_key: str
    max_context_length: int = 2000
    default_model: str = "claude-3-5-sonnet-20241022"
    enable_rate_limit: bool = True

    class Config:
        env_file = ".env"

settings = Settings()
```

---

## 7. V2.0 新增 API（未来）

### 7.1 用户认证

```http
POST /api/v1/auth/register
POST /api/v1/auth/login
GET /api/v1/auth/me
```

### 7.2 会话管理

```http
GET /api/v1/sessions          # 获取用户会话列表
POST /api/v1/sessions         # 创建新会话
GET /api/v1/sessions/{id}     # 获取会话详情
DELETE /api/v1/sessions/{id}  # 删除会话
```

### 7.3 洞察卡片管理

```http
GET /api/v1/insights?session_id={id}  # 获取会话的所有洞察
POST /api/v1/insights/{id}/favorite   # 收藏洞察卡片
DELETE /api/v1/insights/{id}          # 删除洞察卡片
```

---

**文档版本**: 2.0（基于最新产品蓝图）
**最后更新**: 2025-01-19
